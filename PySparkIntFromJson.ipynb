{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa84cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cd9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.streaming import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"FromJson\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f024d7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+--------------------+\n",
      "|PartitionDate|        Status|             request|\n",
      "+-------------+--------------+--------------------+\n",
      "|   2020-06-30|Internal Error|{\"Response\":{\"Mes...|\n",
      "|   2020-06-30|       Success|{\"Response\":{\"Mes...|\n",
      "+-------------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql adaptive query execution adaptive.coalescePartitions.enabled will makr paritions dynamic\n",
    "sc.setLogLevel(\"Error\")\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",3)\n",
    "spark.conf.get(\"spark.sql.shuffle.partitions\")\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\",\"false\")\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\",\"false\")\n",
    "\n",
    "\"\"\"\n",
    "for IOT data, we have a column of String type with Json Data can be achieved in following three ways\n",
    "import from sql functions\n",
    "json_tuple - disadvantage is we should know the column name, is case sensitive\n",
    "from_json - preferable method. We need two things, schema of the json column and data of column\n",
    "to_json - when we have struct type and convert to json, we use to_json\n",
    "\"\"\"\n",
    "filepath = \"file:///C:/Users/venka/PycharmProjects/pythonProject/dataset/\"\n",
    "df = spark.read.option(\"header\",True) \\\n",
    "                .option(\"multiline\",True) \\\n",
    "                .option(\"escape\",\"\\\"\") \\\n",
    "                .csv(filepath + \"IntFromJson.csv\",inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3a47dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PartitionDate: date (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- request: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "626cb6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+--------------------+\n",
      "|PartitionDate|        Status|                  c0|\n",
      "+-------------+--------------+--------------------+\n",
      "|   2020-06-30|Internal Error| {\"MessageId\":15432}|\n",
      "|   2020-06-30|       Success|{\"MessageId\":1543...|\n",
      "+-------------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\",json_tuple(\"request\",\"Response\")).drop(\"request\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad818a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+---------+---------+---------+\n",
      "|PartitionDate|        Status|MessageId| Latitude|Longitude|\n",
      "+-------------+--------------+---------+---------+---------+\n",
      "|   2020-06-30|Internal Error|    15432|     NULL|     NULL|\n",
      "|   2020-06-30|       Success|    15432|-176.2989|   7.3614|\n",
      "+-------------+--------------+---------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Method1 - using json tuple, is case sensitive use same name otherwise column values will be null\n",
    "df.select(\"*\",json_tuple(\"request\",\"Response\")).drop(\"request\") \\\n",
    ".select(\"*\",json_tuple(\"c0\",\"MessageId\",\"Latitude\",\"longitude\").alias(\"MessageId\",\"Latitude\",\"Longitude\")) \\\n",
    ".drop(\"c0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c182463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"Response\":{\"MessageId\" : 15432 }}',\n",
       " '{\"Response\":{\"MessageId\" : 15432,\"Latitude\":\"-176.2989\",\"longitude\":\"7.3614\" }}']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method2 - using from_json\n",
    "#convet to RDD\n",
    "#convert RDD column and read json data\n",
    "df.select(col(\"request\").alias(\"jsoncol\")).rdd.map(lambda x: x.jsoncol).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4a7f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.read.json will accept only rdd or list or string. Here is \n",
    "df_jsonsch = spark.read.json(df.select(col(\"request\").alias(\"jsoncol\")).rdd.map(lambda x: x.jsoncol)).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a3cfd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('Response', StructType([StructField('Latitude', StringType(), True), StructField('MessageId', LongType(), True), StructField('longitude', StringType(), True)]), True)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jsonsch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a14a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fromjson = df.select(\"*\",from_json(\"request\",df_jsonsch).alias(\"jsonstr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2275ab8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PartitionDate: date (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- request: string (nullable = true)\n",
      " |-- jsonstr: struct (nullable = true)\n",
      " |    |-- Response: struct (nullable = true)\n",
      " |    |    |-- Latitude: string (nullable = true)\n",
      " |    |    |-- MessageId: long (nullable = true)\n",
      " |    |    |-- longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fromjson.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd1acae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-------------------------------------------------------------------------------+----------------------------+\n",
      "|PartitionDate|Status        |request                                                                        |jsonstr                     |\n",
      "+-------------+--------------+-------------------------------------------------------------------------------+----------------------------+\n",
      "|2020-06-30   |Internal Error|{\"Response\":{\"MessageId\" : 15432 }}                                            |{{NULL, 15432, NULL}}       |\n",
      "|2020-06-30   |Success       |{\"Response\":{\"MessageId\" : 15432,\"Latitude\":\"-176.2989\",\"longitude\":\"7.3614\" }}|{{-176.2989, 15432, 7.3614}}|\n",
      "+-------------+--------------+-------------------------------------------------------------------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fromjson.show(truncate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25be9281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jsonstr.Response.*'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1 = df_fromjson.schema['jsonstr'].dataType.names[0]\n",
    "chk = \"jsonstr.\" + col1 + \".*\"\n",
    "chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "775b890b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+---------+---------+---------+\n",
      "|PartitionDate|        Status| Latitude|MessageId|longitude|\n",
      "+-------------+--------------+---------+---------+---------+\n",
      "|   2020-06-30|Internal Error|     NULL|    15432|     NULL|\n",
      "|   2020-06-30|       Success|-176.2989|    15432|   7.3614|\n",
      "+-------------+--------------+---------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fromjson.select(\"*\",col(chk)).drop(\"request\",\"jsonstr\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c4c4521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+\n",
      "| Latitude|MessageId|longitude|\n",
      "+---------+---------+---------+\n",
      "|     NULL|    15432|     NULL|\n",
      "|-176.2989|    15432|   7.3614|\n",
      "+---------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fromjson.select(col(chk)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3ee0f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   to_json(Response)|\n",
      "+--------------------+\n",
      "| {\"MessageId\":15432}|\n",
      "|{\"Latitude\":\"-176...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Method3 to_json\n",
    "df_fromjson.select(col(\"jsonstr.*\")).select(to_json(col(\"Response\"))).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
