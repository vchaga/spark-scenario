{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa84cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cd9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.streaming import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"UnionName\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f024d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql adaptive query execution adaptive.coalescePartitions.enabled will makr paritions dynamic\n",
    "sc.setLogLevel(\"Error\")\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",3)\n",
    "spark.conf.get(\"spark.sql.shuffle.partitions\")\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\",\"false\")\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\",\"false\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\",True)\n",
    "spark.conf.set(\"spark.sql.execution.arrow.fallback.enabled\",True)\n",
    "\n",
    "\"\"\"\n",
    "Merge two data frames use, of Union and UnionByName\n",
    "\n",
    "1.Union - merge two data frame wrt to position of column and datatype of column in data\n",
    "\n",
    "2.Merge by position and data type using union and select\n",
    "\n",
    "3.UnionByName Merge two data frame wrt name of column in data\n",
    "  Union by name works for non matching columns(df1 - 3 cols, df2 - 4 cols) in two data frames as well. Appends null\n",
    "  df1.unionByName(df2,allowMissingColumns=True).show()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#WithoutInferSchema\n",
    "#headerTrue will read first row and assign column names but type is String for all\n",
    "#spark job created to read first column\n",
    "filepath = \"file:///C:/Users/venka/PycharmProjects/pythonProject/dataset/\"\n",
    "df = spark.read.option(\"header\",True) \\\n",
    "            .option(\"inferSchema\",True) \\\n",
    "            .option(\"delimiter\",\",\") \\\n",
    "            .csv(filepath + \"IntPersonal_transactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a47dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a = [[\"2020\",\"Dhanush\",\"Karnan\"]]\n",
    "list_b = [[\"Vikram\",\"2020\",\"Master\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d2d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame(list_a,(\"year\",\"cast\",\"movie\"))\n",
    "df2 = spark.createDataFrame(list_b,(\"cast\",\"year\",\"movie\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1693bccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------+\n",
      "|  cast|year| movie|\n",
      "+------+----+------+\n",
      "|Vikram|2020|Master|\n",
      "+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f00a9053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|  year|   cast| movie|\n",
      "+------+-------+------+\n",
      "|  2020|Dhanush|Karnan|\n",
      "|Vikram|   2020|Master|\n",
      "+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Union - merge two data frame wrt to position of column and datatype of column in data\n",
    "df1.union(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3328a39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+------+\n",
      "|year|   cast| movie|\n",
      "+----+-------+------+\n",
      "|2020|Dhanush|Karnan|\n",
      "|2020| Vikram|Master|\n",
      "+----+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Merge by position and data type using union\n",
    "in_df2 = df2.select(\"year\",\"cast\",\"movie\")\n",
    "df1.union(in_df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "418fa70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+------+\n",
      "|year|   cast| movie|\n",
      "+----+-------+------+\n",
      "|2020|Dhanush|Karnan|\n",
      "|2020| Vikram|Master|\n",
      "+----+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#UnionByName Merge two data frame wrt name of column in data\n",
    "#Union by name works for non matching columns in two data frames as well. Appends null\n",
    "df1.unionByName(df2,allowMissingColumns=True).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
