{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa84cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87cd9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.streaming import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Accumulators\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f024d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql adaptive query execution adaptive.coalescePartitions.enabled will makr paritions dynamic\n",
    "sc.setLogLevel(\"Error\")\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",3)\n",
    "spark.conf.get(\"spark.sql.shuffle.partitions\")\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\",\"false\")\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\",\"false\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\",True)\n",
    "spark.conf.set(\"spark.sql.execution.arrow.fallback.enabled\",True)\n",
    "\n",
    "\"\"\"\n",
    "Alternative to DF count operation\n",
    "1.Read the input\n",
    "2.Apply filter operation\n",
    "3.groupBy aggregate\n",
    "4.show grouped data\n",
    "\n",
    "get count of data without using count operation\n",
    "\n",
    "accumulator are counter or shared variable in spark\n",
    "accumulator has four call, accum_parameter,add,value\n",
    "accumulator should be applied on action, applying on transformation would misled the count\n",
    "\"\"\"\n",
    "\n",
    "#WithoutInferSchema\n",
    "#headerTrue will read first row and assign column names but type is String for all\n",
    "#spark job created to read first column\n",
    "filepath = \"file:///C:/Users/venka/PycharmProjects/pythonProject/dataset/\"\n",
    "df = spark.read.option(\"header\",True) \\\n",
    "            .option(\"delimiter\",\"|\") \\\n",
    "            .option(\"inferSchema\",True) \\\n",
    "            .csv(filepath + \"IntUspopulation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3a47dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23d2d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter data\n",
    "df1 = df.filter(\"State_code <> 'NY'\").groupBy(\"city\").sum(\"2019_estimate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1693bccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f00a9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accumulator\n",
    "dfcounter = spark.sparkContext.accumulator(0)\n",
    "filtercounter = spark.sparkContext.accumulator(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6c1e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.foreach(lambda x: dfcounter.add(1))\n",
    "df1.foreach(lambda x: filtercounter.add(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3be2bd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    }
   ],
   "source": [
    "print(dfcounter.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3760257a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "print(filtercounter.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
