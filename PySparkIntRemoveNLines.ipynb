{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa84cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cd9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.streaming import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"PandastoSpark\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f024d7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Site', 'www.learntospark.com'],\n",
       " ['Desccription', '\"Complete guide to learn Spark', 'AI', 'ML\"'],\n",
       " ['Page Views of each blog'],\n",
       " ['20200817-20200817'],\n",
       " [''],\n",
       " ['Total data in page', '12'],\n",
       " [''],\n",
       " ['Page', 'Date', 'Pageviews', 'Unique_Pageviews', 'Sessions'],\n",
       " ['Guide to Install Spark', '2020-08-17', '1140', '986', '800'],\n",
       " ['Spark MAP vs FlatMap', '2020-08-17', '836', '800', '128'],\n",
       " ['Spark Architechture', '2020-08-17', '1569', '1345', '1400'],\n",
       " ['Azure Function for Mp3 to text', '2020-08-17', '350', '245', '234'],\n",
       " ['Scala Vs Python', '2020-08-17', '200', '150', '130'],\n",
       " ['Spark Window Function', '2020-08-17', '789', '546', '560'],\n",
       " ['Natural Language Processing', '2020-08-17', '467', '456', '100'],\n",
       " ['Spark Linear Interpolation - Time Series',\n",
       "  '2020-08-17',\n",
       "  '698',\n",
       "  '345',\n",
       "  '349'],\n",
       " ['Spark case statement', '2020-08-17', '234', '196', '120'],\n",
       " ['Spark Scenario Based Questions', '2020-08-17', '712', '329', '137'],\n",
       " ['Spark v3.0 Delta Lake', '2020-08-17', '333', '198', '39'],\n",
       " ['Screen Recorder App using Python', '2020-08-17', '766', '567', '344'],\n",
       " ['Spark trick with Show()', '2020-08-17', '108', '35', '24'],\n",
       " ['Spark Cache() Vs Persist', '2020-08-17', '587', '432', '300'],\n",
       " ['Image Processing text to audio', '2020-08-17', '384', '123', '84']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sql adaptive query execution adaptive.coalescePartitions.enabled will makr paritions dynamic\n",
    "sc.setLogLevel(\"Error\")\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",3)\n",
    "spark.conf.get(\"spark.sql.shuffle.partitions\")\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\",\"false\")\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\",\"false\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\",True)\n",
    "spark.conf.set(\"spark.sql.execution.arrow.fallback.enabled\",True)\n",
    "\n",
    "\"\"\"\n",
    "Pandas DF to spark DF\n",
    "use mapParititonsWithIndex\n",
    "\"\"\"\n",
    "\n",
    "#WithoutInferSchema\n",
    "#headerTrue will read first row and assign column names but type is String for all\n",
    "#spark job created to read first column\n",
    "filepath = \"file:///C:/Users/venka/PycharmProjects/pythonProject/dataset/\"\n",
    "df = sc.textFile(filepath + \"IntPageview.csv\").map(lambda x: x.split(\",\"))\n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3a47dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23d2d99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Guide to Install Spark', '2020-08-17', '1140', '986', '800'],\n",
       " ['Spark MAP vs FlatMap', '2020-08-17', '836', '800', '128'],\n",
       " ['Spark Architechture', '2020-08-17', '1569', '1345', '1400'],\n",
       " ['Azure Function for Mp3 to text', '2020-08-17', '350', '245', '234'],\n",
       " ['Scala Vs Python', '2020-08-17', '200', '150', '130'],\n",
       " ['Spark Window Function', '2020-08-17', '789', '546', '560'],\n",
       " ['Natural Language Processing', '2020-08-17', '467', '456', '100'],\n",
       " ['Spark Linear Interpolation - Time Series',\n",
       "  '2020-08-17',\n",
       "  '698',\n",
       "  '345',\n",
       "  '349'],\n",
       " ['Spark case statement', '2020-08-17', '234', '196', '120'],\n",
       " ['Spark Scenario Based Questions', '2020-08-17', '712', '329', '137'],\n",
       " ['Spark v3.0 Delta Lake', '2020-08-17', '333', '198', '39'],\n",
       " ['Screen Recorder App using Python', '2020-08-17', '766', '567', '344'],\n",
       " ['Spark trick with Show()', '2020-08-17', '108', '35', '24'],\n",
       " ['Spark Cache() Vs Persist', '2020-08-17', '587', '432', '300'],\n",
       " ['Image Processing text to audio', '2020-08-17', '384', '123', '84']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Difference between map(row by row basis) and mapPartitionsWithIndex(parition by partition)\n",
    "#Apply index to partition wise and omit if the partition index is zero\n",
    "#Here iter[8:] is remove lines upto 8 from zero\n",
    "\n",
    "rdd_drop = df.mapPartitionsWithIndex(lambda idx,iter: list(iter)[8:] if (idx==0) else iter)\n",
    "rdd_drop.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1693bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = [\"Page\", \"Date\", \"PageViews\", \"UniqueViews\",\"Session\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89b65bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame(rdd_drop,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4022d31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+-----------+-------+\n",
      "|                Page|      Date|PageViews|UniqueViews|Session|\n",
      "+--------------------+----------+---------+-----------+-------+\n",
      "|Guide to Install ...|2020-08-17|     1140|        986|    800|\n",
      "|Spark MAP vs FlatMap|2020-08-17|      836|        800|    128|\n",
      "| Spark Architechture|2020-08-17|     1569|       1345|   1400|\n",
      "|Azure Function fo...|2020-08-17|      350|        245|    234|\n",
      "|     Scala Vs Python|2020-08-17|      200|        150|    130|\n",
      "|Spark Window Func...|2020-08-17|      789|        546|    560|\n",
      "|Natural Language ...|2020-08-17|      467|        456|    100|\n",
      "|Spark Linear Inte...|2020-08-17|      698|        345|    349|\n",
      "|Spark case statement|2020-08-17|      234|        196|    120|\n",
      "|Spark Scenario Ba...|2020-08-17|      712|        329|    137|\n",
      "|Spark v3.0 Delta ...|2020-08-17|      333|        198|     39|\n",
      "|Screen Recorder A...|2020-08-17|      766|        567|    344|\n",
      "|Spark trick with ...|2020-08-17|      108|         35|     24|\n",
      "|Spark Cache() Vs ...|2020-08-17|      587|        432|    300|\n",
      "|Image Processing ...|2020-08-17|      384|        123|     84|\n",
      "+--------------------+----------+---------+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3784fbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Guide to Install Spark,2020-08-17,1140,986,800', 8),\n",
       " ('Spark MAP vs FlatMap,2020-08-17,836,800,128', 9),\n",
       " ('Spark Architechture,2020-08-17,1569,1345,1400', 10),\n",
       " ('Azure Function for Mp3 to text,2020-08-17,350,245,234', 11),\n",
       " ('Scala Vs Python,2020-08-17,200,150,130', 12),\n",
       " ('Spark Window Function,2020-08-17,789,546,560', 13),\n",
       " ('Natural Language Processing,2020-08-17,467,456,100', 14),\n",
       " ('Spark Linear Interpolation - Time Series,2020-08-17,698,345,349', 15),\n",
       " ('Spark case statement,2020-08-17,234,196,120', 16),\n",
       " ('Spark Scenario Based Questions,2020-08-17,712,329,137', 17),\n",
       " ('Spark v3.0 Delta Lake,2020-08-17,333,198,39', 18),\n",
       " ('Screen Recorder App using Python,2020-08-17,766,567,344', 19),\n",
       " ('Spark trick with Show(),2020-08-17,108,35,24', 20),\n",
       " ('Spark Cache() Vs Persist,2020-08-17,587,432,300', 21),\n",
       " ('Image Processing text to audio,2020-08-17,384,123,84', 22)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile(filepath + \"IntPageview.csv\").zipWithIndex().filter(lambda x: x[1]>= 8).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d337557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+-----------+-------+\n",
      "|                Page|      Date|PageViews|UniqueViews|Session|\n",
      "+--------------------+----------+---------+-----------+-------+\n",
      "|Guide to Install ...|2020-08-17|     1140|        986|    800|\n",
      "|Spark MAP vs FlatMap|2020-08-17|      836|        800|    128|\n",
      "| Spark Architechture|2020-08-17|     1569|       1345|   1400|\n",
      "|Azure Function fo...|2020-08-17|      350|        245|    234|\n",
      "|     Scala Vs Python|2020-08-17|      200|        150|    130|\n",
      "|Spark Window Func...|2020-08-17|      789|        546|    560|\n",
      "|Natural Language ...|2020-08-17|      467|        456|    100|\n",
      "|Spark Linear Inte...|2020-08-17|      698|        345|    349|\n",
      "|Spark case statement|2020-08-17|      234|        196|    120|\n",
      "|Spark Scenario Ba...|2020-08-17|      712|        329|    137|\n",
      "|Spark v3.0 Delta ...|2020-08-17|      333|        198|     39|\n",
      "|Screen Recorder A...|2020-08-17|      766|        567|    344|\n",
      "|Spark trick with ...|2020-08-17|      108|         35|     24|\n",
      "|Spark Cache() Vs ...|2020-08-17|      587|        432|    300|\n",
      "|Image Processing ...|2020-08-17|      384|        123|     84|\n",
      "+--------------------+----------+---------+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#(As zipWithIndex starts with 0) , here index column is present at last and is removed with second map transformation\n",
    "#the map transformation splits each line by a comma (,), converting it into a list of strings. \n",
    "zipdf = sc.textFile(filepath + \"IntPageview.csv\").zipWithIndex().filter(lambda x: x[1]>= 8).map(lambda x: x[0].split(\",\"))\n",
    "df3 = spark.createDataFrame(zipdf,schema)\n",
    "df3.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
