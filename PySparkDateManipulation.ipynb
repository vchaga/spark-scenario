{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa84cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87cd9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"DateManipulation\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f024d7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- input_date: string (nullable = true)\n",
      "\n",
      "+-------------------+\n",
      "|         input_date|\n",
      "+-------------------+\n",
      "|2024/01/01 01:00 AM|\n",
      "|2024/02/03 03:00 AM|\n",
      "|2023/04/06 09:00 PM|\n",
      "|2022/08/02 06:00 PM|\n",
      "|2024/02/01 10:00 AM|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_list = [\n",
    "    [\"2024/01/01 01:00 AM\"],\n",
    "    [\"2024/02/03 03:00 AM\"],\n",
    "    [\"2023/04/06 09:00 PM\"],\n",
    "    [\"2022/08/02 06:00 PM\"],\n",
    "    [\"2024/02/01 10:00 AM\"]\n",
    "]\n",
    "\n",
    "date_schema = [\"input_date\"]\n",
    "df= spark.createDataFrame(date_list,date_schema)\n",
    "df.printSchema()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b30b051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d9b20cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- input_date: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- time: timestamp (nullable = true)\n",
      "\n",
      "+-------------------+----------+-------------------+\n",
      "|         input_date|      date|               time|\n",
      "+-------------------+----------+-------------------+\n",
      "|2024/01/01 01:00 AM|2024-01-01|2024-01-01 01:00:00|\n",
      "|2024/02/03 03:00 AM|2024-02-03|2024-02-03 03:00:00|\n",
      "|2023/04/06 09:00 PM|2023-04-06|2023-04-06 21:00:00|\n",
      "|2022/08/02 06:00 PM|2022-08-02|2022-08-02 18:00:00|\n",
      "|2024/02/01 10:00 AM|2024-02-01|2024-02-01 10:00:00|\n",
      "+-------------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date,to_timestamp,date_format\n",
    "\n",
    "#total available functions are 3 to_date,to_timestamp,date_format\n",
    "\n",
    "df2 = df.withColumn(\"date\",to_date(col(\"input_date\"),\"yyyy/MM/dd\")) \\\n",
    "        .withColumn(\"time\",to_timestamp(\"input_date\",\"yyyy/MM/dd hh:mm a\"))\n",
    "\n",
    "df2.printSchema()\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b9a3585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-------------------+----+-----+---+----+------+---------+-------+----------+\n",
      "|         input_date|      date|               time|year|month|day|hour|minute|dayofweek|quarter|weekofyear|\n",
      "+-------------------+----------+-------------------+----+-----+---+----+------+---------+-------+----------+\n",
      "|2024/01/01 01:00 AM|2024-01-01|2024-01-01 01:00:00|2024|    1|  1|   1|     0|        2|      1|         1|\n",
      "|2024/02/03 03:00 AM|2024-02-03|2024-02-03 03:00:00|2024|    2|  3|   3|     0|        7|      1|         5|\n",
      "|2023/04/06 09:00 PM|2023-04-06|2023-04-06 21:00:00|2023|    4|  6|  21|     0|        5|      2|        14|\n",
      "|2022/08/02 06:00 PM|2022-08-02|2022-08-02 18:00:00|2022|    8|  2|  18|     0|        3|      3|        31|\n",
      "|2024/02/01 10:00 AM|2024-02-01|2024-02-01 10:00:00|2024|    2|  1|  10|     0|        5|      1|         5|\n",
      "+-------------------+----------+-------------------+----+-----+---+----+------+---------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year,month,dayofmonth,hour,minute,second,dayofweek,quarter,weekofyear\n",
    "\n",
    "df3 = df2.withColumn(\"year\",year(\"time\")) \\\n",
    ".withColumn(\"month\",month(\"time\")) \\\n",
    ".withColumn(\"day\",dayofmonth(\"time\")) \\\n",
    ".withColumn(\"hour\",hour(\"time\")) \\\n",
    ".withColumn(\"minute\",minute(\"time\")) \\\n",
    ".withColumn(\"dayofweek\",dayofweek(\"time\")) \\\n",
    ".withColumn(\"quarter\",quarter(\"time\")) \\\n",
    ".withColumn(\"weekofyear\",weekofyear(\"time\"))\n",
    "\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b19fd483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-------------------+---------+----------+------------+\n",
      "|         input_date|      date|               time|dayofweek|dayinwords|monthinwords|\n",
      "+-------------------+----------+-------------------+---------+----------+------------+\n",
      "|2024/01/01 01:00 AM|2024-01-01|2024-01-01 01:00:00|        2|    Monday|     January|\n",
      "|2024/02/03 03:00 AM|2024-02-03|2024-02-03 03:00:00|        7|  Saturday|    February|\n",
      "|2023/04/06 09:00 PM|2023-04-06|2023-04-06 21:00:00|        5|  Thursday|       April|\n",
      "|2022/08/02 06:00 PM|2022-08-02|2022-08-02 18:00:00|        3|   Tuesday|      August|\n",
      "|2024/02/01 10:00 AM|2024-02-01|2024-02-01 10:00:00|        5|  Thursday|    February|\n",
      "+-------------------+----------+-------------------+---------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.withColumn(\"dayofweek\",dayofweek(\"time\")) \\\n",
    ".withColumn(\"dayinwords\",date_format(\"time\", \"EEEE\")) \\\n",
    ".withColumn(\"monthinwords\",date_format(\"time\",\"LLLL\")) \\\n",
    ".show()\n",
    "\n",
    "#Use only three characters for EEE or LLL for truncated names and in four characters(EEEE/LLLL) for full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94441768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-------------------+-----------+----------+----------+--------+-------------------+\n",
      "|         input_date|      date|               time|currentdate|   dateadd|   datesub|datediff|         date_trunc|\n",
      "+-------------------+----------+-------------------+-----------+----------+----------+--------+-------------------+\n",
      "|2024/01/01 01:00 AM|2024-01-01|2024-01-01 01:00:00| 2024-01-01|2024-01-06|2023-12-27|       0|2024-01-01 00:00:00|\n",
      "|2024/02/03 03:00 AM|2024-02-03|2024-02-03 03:00:00| 2024-01-01|2024-02-08|2024-01-29|     -33|2024-02-01 00:00:00|\n",
      "|2023/04/06 09:00 PM|2023-04-06|2023-04-06 21:00:00| 2024-01-01|2023-04-11|2023-04-01|     270|2023-04-01 00:00:00|\n",
      "|2022/08/02 06:00 PM|2022-08-02|2022-08-02 18:00:00| 2024-01-01|2022-08-07|2022-07-28|     517|2022-08-01 00:00:00|\n",
      "|2024/02/01 10:00 AM|2024-02-01|2024-02-01 10:00:00| 2024-01-01|2024-02-06|2024-01-27|     -31|2024-02-01 00:00:00|\n",
      "+-------------------+----------+-------------------+-----------+----------+----------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date,date_add,date_sub,date_trunc,datediff\n",
    "\n",
    "df2.withColumn(\"currentdate\",current_date()) \\\n",
    ".withColumn(\"dateadd\",date_add(\"time\", 5)) \\\n",
    ".withColumn(\"datesub\",date_sub(\"time\", 5)) \\\n",
    ".withColumn(\"datediff\",datediff(current_date(), \"time\")) \\\n",
    ".withColumn(\"date_trunc\",date_trunc(\"mm\", \"time\")) \\\n",
    ".show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47a09d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function date_add in module pyspark.sql.functions:\n",
      "\n",
      "date_add(start: 'ColumnOrName', days: Union[ForwardRef('ColumnOrName'), int]) -> pyspark.sql.column.Column\n",
      "    Returns the date that is `days` days after `start`. If `days` is a negative value\n",
      "    then these amount of days will be deducted from `start`.\n",
      "    \n",
      "    .. versionadded:: 1.5.0\n",
      "    \n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    start : :class:`~pyspark.sql.Column` or str\n",
      "        date column to work on.\n",
      "    days : :class:`~pyspark.sql.Column` or str or int\n",
      "        how many days after the given date to calculate.\n",
      "        Accepts negative value as well to calculate backwards in time.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    :class:`~pyspark.sql.Column`\n",
      "        a date after/before given number of days.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = spark.createDataFrame([('2015-04-08', 2,)], ['dt', 'add'])\n",
      "    >>> df.select(date_add(df.dt, 1).alias('next_date')).collect()\n",
      "    [Row(next_date=datetime.date(2015, 4, 9))]\n",
      "    >>> df.select(date_add(df.dt, df.add.cast('integer')).alias('next_date')).collect()\n",
      "    [Row(next_date=datetime.date(2015, 4, 10))]\n",
      "    >>> df.select(date_add('dt', -1).alias('prev_date')).collect()\n",
      "    [Row(prev_date=datetime.date(2015, 4, 7))]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(date_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532fd7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
