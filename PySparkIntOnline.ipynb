{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa84cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87cd9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.streaming import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Online\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f024d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql adaptive query execution adaptive.coalescePartitions.enabled will makr paritions dynamic\n",
    "sc.setLogLevel(\"Error\")\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",3)\n",
    "spark.conf.get(\"spark.sql.shuffle.partitions\")\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\",\"false\")\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\",\"false\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\",True)\n",
    "spark.conf.set(\"spark.sql.execution.arrow.fallback.enabled\",True)\n",
    "\n",
    "\"\"\"\n",
    "Online codeing round\n",
    "https://www.learntospark.com/2020/11/spark-interview-question-coding-round.html\n",
    "https://files.grouplens.org/datasets/movielens/ml-latest-small-README.html\n",
    "\n",
    "1.Create a CSV file containing list of movies with number of users who rated the movie and average rating per movie. \n",
    "The file has to with three columns, i.e, MovieId, No of users, Average rating. Header column is not required. \n",
    "[Note - Use RDD for this Task (No Dataset or No Dataframes)]\n",
    "2.Create a CSV file containing list of unique Genres and number of movies under each genres. \n",
    "The file should contain two columns i.e, Genres, No of movies. Column headers are not required. \n",
    "[Note - Use RDD for this Task (No Dataset or No Dataframes)].\n",
    "3.Generate a output of format parquet that contains top 100 movies based on their ratings. \n",
    "This should have following fields in it. i.e, Rank (from 1 - 100), MovieId, Title, Average Rating.\n",
    "\"\"\"\n",
    "\n",
    "#WithoutInferSchema\n",
    "#headerTrue will read first row and assign column names but type is String for all\n",
    "#spark job created to read first column\n",
    "filepath = \"file:///C:/Users/venka/PycharmProjects/pythonProject/dataset/\"\n",
    "users = sc.textFile(filepath + \"Online/ratings.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3a47dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1::1193::5::978300760',\n",
       " '1::661::3::978302109',\n",
       " '1::914::3::978301968',\n",
       " '1::3408::4::978300275',\n",
       " '1::2355::5::978824291']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a CSV file with MovieId, No of users, Average rating\n",
    "#Create a CSV file containing list of movies with number of users who rated the movie and average rating per movie. \n",
    "#The file has to with three columns, i.e, MovieId, No of users, Average rating. Header column is not required. \n",
    "#[Note - Use RDD for this Task (No Dataset or No Dataframes)]\n",
    "ratings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23d2d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_sch = StructType([\n",
    "    StructField(\"userId\",IntegerType(),False),\n",
    "    StructField(\"movieId\",IntegerType(),False),\n",
    "    StructField(\"rating\",IntegerType(),False),\n",
    "    StructField(\"timestamp\",IntegerType(),False)\n",
    "])\n",
    "\n",
    "ratings = sc.textFile(filepath + \"Online/ratings.dat\")\n",
    "\n",
    "# Create RDD with (MovieId, (Rating, 1))\n",
    "movie_ratings = ratings.map(lambda line: (int(line.split(\"::\")[1]), (float(line.split(\"::\")[2]), 1)))\n",
    "\n",
    "# Aggregate ratings by MovieId\n",
    "total_ratings = movie_ratings.reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "\n",
    "# Calculate average rating per movie\n",
    "average_ratings = total_ratings.mapValues(lambda x: x[0] / x[1])\n",
    "\n",
    "# Count the number of users who rated each movie\n",
    "user_counts = total_ratings.mapValues(lambda x: x[1])\n",
    "\n",
    "# Combine MovieId, No of users, Average rating\n",
    "result = user_counts.join(average_ratings)\n",
    "\n",
    "# Save the result as a CSV file\n",
    "result.map(lambda x: f\"{x[0]},{x[1][0]},{x[1][1]}\").saveAsTextFile(filepath + \"Online/ratings_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1693bccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1193, 1725), (661, 525), (914, 636), (3408, 1315), (2355, 1703)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_counts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89b65bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1193, (5.0, 1)),\n",
       " (661, (3.0, 1)),\n",
       " (914, (3.0, 1)),\n",
       " (3408, (4.0, 1)),\n",
       " (2355, (5.0, 1))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4022d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Create a CSV file containing list of unique Genres and number of movies under each genres. \n",
    "#The file should contain two columns i.e, Genres, No of movies. Column headers are not required. \n",
    "#[Note - Use RDD for this Task (No Dataset or No Dataframes)].\n",
    "\n",
    "movies = sc.textFile(filepath + \"Online/movies.dat\")\n",
    "\n",
    "# Extract Genres from each movie\n",
    "movie_genres = movies.flatMap(lambda line: line.split(\"::\")[2].split(\"|\"))\n",
    "\n",
    "# Count the occurrences of each genre\n",
    "genre_counts = movie_genres.map(lambda genre: (genre, 1)).reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# Save the result as a CSV file\n",
    "genre_counts.map(lambda x: f\"{x[0]},{x[1]}\").saveAsTextFile(filepath + \"Online/genre_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "570fc1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"1::Toy Story (1995)::Animation|Children's|Comedy\",\n",
       " \"2::Jumanji (1995)::Adventure|Children's|Fantasy\",\n",
       " '3::Grumpier Old Men (1995)::Comedy|Romance',\n",
       " '4::Waiting to Exhale (1995)::Comedy|Drama',\n",
       " '5::Father of the Bride Part II (1995)::Comedy']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "92d6a852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Animation', 105),\n",
       " (\"Children's\", 251),\n",
       " ('Comedy', 1200),\n",
       " ('Adventure', 283),\n",
       " ('Fantasy', 68),\n",
       " ('Romance', 471),\n",
       " ('Drama', 1603),\n",
       " ('Action', 503),\n",
       " ('Crime', 211),\n",
       " ('Thriller', 492),\n",
       " ('Horror', 343),\n",
       " ('Sci-Fi', 276),\n",
       " ('Documentary', 127),\n",
       " ('War', 143),\n",
       " ('Musical', 114),\n",
       " ('Mystery', 106),\n",
       " ('Film-Noir', 44),\n",
       " ('Western', 68)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_counts.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "824b26b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Generate a Parquet file with top 100 movies based on ratings\n",
    "#Generate a output of format parquet that contains top 100 movies based on their ratings. \n",
    "#This should have following fields in it. i.e, Rank (from 1 - 100), MovieId, Title, Average Rating.\n",
    "\n",
    "# Read ratings data into a DataFrame\n",
    "ratings_df = spark.read.text(filepath + \"Online/ratings.dat\")  # Replace with the actual path\n",
    "\n",
    "# Create a DataFrame with MovieId, Average Rating\n",
    "average_ratings_df = ratings_df.selectExpr(\"CAST(split(value, '::')[1] AS INT) AS MovieId\",\n",
    "                                           \"CAST(split(value, '::')[2] AS FLOAT) AS Rating\")\n",
    "\n",
    "# Calculate average rating per movie\n",
    "average_ratings_df = average_ratings_df.groupBy(\"MovieId\").agg({\"Rating\": \"avg\"})\n",
    "\n",
    "# Rank movies based on average rating\n",
    "ranked_movies_df = average_ratings_df.orderBy(\"avg(Rating)\", ascending=False) \\\n",
    "        .limit(100).withColumnRenamed(\"avg(Rating)\", \"AverageRating\")\n",
    "\n",
    "# Read movies data into a DataFrame\n",
    "movies_df = spark.read.text(filepath + \"Online/movies.dat\")  # Replace with the actual path\n",
    "\n",
    "# Extract MovieId and Title from movies data\n",
    "movies_df = movies_df.selectExpr(\"CAST(split(value, '::')[0] AS INT) AS MovieId\", \"split(value, '::')[1] AS Title\")\n",
    "\n",
    "# Join with ranked movies to get the final result\n",
    "top_movies_df = ranked_movies_df.join(movies_df, \"MovieId\") \\\n",
    "        .withColumn(\"Rank\", row_number().over(Window.orderBy(\"AverageRating\")))\n",
    "\n",
    "# Save the result as a Parquet file\n",
    "#top_movies_df.write.parquet(filepath + \"Online/top100_movies\")\n",
    "top_movies_df.write.csv(filepath + \"Online/top100_movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "43af9c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|MovieId|       avg(Rating)|\n",
      "+-------+------------------+\n",
      "|   1193| 4.390724637681159|\n",
      "|    661|3.4647619047619047|\n",
      "|    914| 4.154088050314465|\n",
      "|   2355| 3.854374633000587|\n",
      "|    919| 4.247962747380675|\n",
      "|   2918|  4.11744738628649|\n",
      "|   1035| 3.931972789115646|\n",
      "|   2791|3.9711149624494513|\n",
      "|   3105|3.7808823529411764|\n",
      "|    720| 4.426940639269406|\n",
      "|   1721|3.5834411384217333|\n",
      "|   2294| 3.483720930232558|\n",
      "|   3186|3.4779582366589326|\n",
      "|   1566| 3.279317697228145|\n",
      "|    783| 3.223076923076923|\n",
      "|   1961| 4.053383458646617|\n",
      "|   1962|3.8773006134969323|\n",
      "|   2692| 4.224813432835821|\n",
      "|   1028| 3.894164193867458|\n",
      "|   1029| 3.688380281690141|\n",
      "+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_ratings_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
