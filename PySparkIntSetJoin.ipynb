{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa84cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cd9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.streaming import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"SetOperations\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f024d7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+\n",
      "|Roll_no|Student_name|Mobile|\n",
      "+-------+------------+------+\n",
      "|   1001|       Akash|123456|\n",
      "|   1002|         Anu|903675|\n",
      "|   1003|     Prakash| 23456|\n",
      "|   1004|        Mani|337456|\n",
      "|   1005|       Manju|820456|\n",
      "|   1006|      Magesh|987456|\n",
      "|   1007|        Balu|654321|\n",
      "|   1008|      Barath|765456|\n",
      "|   1009|     Patrick| 98765|\n",
      "+-------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql adaptive query execution adaptive.coalescePartitions.enabled will makr paritions dynamic\n",
    "sc.setLogLevel(\"Error\")\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",3)\n",
    "spark.conf.get(\"spark.sql.shuffle.partitions\")\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\",\"false\")\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\",\"false\")\n",
    "\n",
    "\"\"\"\n",
    "Set vs Join operations\n",
    "records present in both files and files present in one file and not the other\n",
    "\n",
    "Set - Set operators such as intersect, subtract, union etc\n",
    "Join - left semi, left anti etc\n",
    "\"\"\"\n",
    "\n",
    "#WithoutInferSchema\n",
    "#headerTrue will read first row and assign column names but type is String for all\n",
    "#spark job created to read first column\n",
    "filepath = \"file:///C:/Users/venka/PycharmProjects/pythonProject/dataset/\"\n",
    "masterdf = spark.read.option(\"header\",True) \\\n",
    "                .option(\"delimiter\",\"|\") \\\n",
    "                .csv(filepath + \"IntSetJoin1.csv\",inferSchema=True)\n",
    "masterdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3a47dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+\n",
      "|Roll_no|Student_name|Mobile|\n",
      "+-------+------------+------+\n",
      "|   1001|       Akash|123456|\n",
      "|   1002|         Anu|903675|\n",
      "|   1003|     Prakash| 23456|\n",
      "|   1004|        Mani|337456|\n",
      "|   1008|      Barath|765456|\n",
      "|   1009|     Patrick| 98765|\n",
      "+-------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dailydf = spark.read.option(\"header\",True) \\\n",
    "                .option(\"delimiter\",\"|\") \\\n",
    "                .csv(filepath + \"IntSetJoin2.csv\",inferSchema=True)\n",
    "dailydf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23d2d99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+\n",
      "|Roll_no|Student_name|Mobile|\n",
      "+-------+------------+------+\n",
      "|   1001|       Akash|123456|\n",
      "|   1004|        Mani|337456|\n",
      "|   1009|     Patrick| 98765|\n",
      "|   1002|         Anu|903675|\n",
      "|   1003|     Prakash| 23456|\n",
      "|   1008|      Barath|765456|\n",
      "+-------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Set operators - union, unionAll, intersect, intersectAll, subtract, exceptAll\n",
    "#Join operators - inner, outer, leftOuter, rightOuter, leftSemi, leftAnti, cartesian (we dont have except, only exceptAll)\n",
    "\n",
    "#union, unionAll is same , duplicates are accounted in unionAll\n",
    "#intersect will indirectly call leftSemi through broadcast join\n",
    "masterdf.intersect(dailydf).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fb66980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+\n",
      "|Roll_no|Student_name|Mobile|\n",
      "+-------+------------+------+\n",
      "|   1001|       Akash|123456|\n",
      "|   1004|        Mani|337456|\n",
      "|   1009|     Patrick| 98765|\n",
      "|   1002|         Anu|903675|\n",
      "|   1003|     Prakash| 23456|\n",
      "|   1008|      Barath|765456|\n",
      "+-------+------------+------+\n",
      "\n",
      "== Physical Plan ==\n",
      "*(5) Project [Roll_no#40, Student_name#41, Mobile#42]\n",
      "+- Generate replicaterows(min_count#381L, Roll_no#40, Student_name#41, Mobile#42), [Roll_no#40, Student_name#41, Mobile#42], false, [Roll_no#40, Student_name#41, Mobile#42]\n",
      "   +- *(4) Project [Roll_no#40, Student_name#41, Mobile#42, if ((vcol1_count#378L > vcol2_count#380L)) vcol2_count#380L else vcol1_count#378L AS min_count#381L]\n",
      "      +- *(4) Filter ((vcol1_count#378L >= 1) AND (vcol2_count#380L >= 1))\n",
      "         +- *(4) HashAggregate(keys=[Roll_no#40, Student_name#41, Mobile#42], functions=[count(vcol1#373), count(vcol2#376)])\n",
      "            +- Exchange hashpartitioning(Roll_no#40, Student_name#41, Mobile#42, 3), ENSURE_REQUIREMENTS, [plan_id=719]\n",
      "               +- *(3) HashAggregate(keys=[Roll_no#40, Student_name#41, Mobile#42], functions=[partial_count(vcol1#373), partial_count(vcol2#376)])\n",
      "                  +- Union\n",
      "                     :- *(1) Project [true AS vcol1#373, null AS vcol2#376, Roll_no#40, Student_name#41, Mobile#42]\n",
      "                     :  +- FileScan csv [Roll_no#40,Student_name#41,Mobile#42] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/venka/PycharmProjects/pythonProject/dataset/IntSetJoin1..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Roll_no:int,Student_name:string,Mobile:int>\n",
      "                     +- *(2) Project [null AS vcol1#374, true AS vcol2#375, Roll_no#120, Student_name#121, Mobile#122]\n",
      "                        +- FileScan csv [Roll_no#120,Student_name#121,Mobile#122] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/venka/PycharmProjects/pythonProject/dataset/IntSetJoin2..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Roll_no:int,Student_name:string,Mobile:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "masterdf.intersectAll(dailydf).show()\n",
    "masterdf.intersectAll(dailydf).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4022d31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+\n",
      "|Roll_no|Student_name|Mobile|\n",
      "+-------+------------+------+\n",
      "|   1001|       Akash|123456|\n",
      "|   1002|         Anu|903675|\n",
      "|   1003|     Prakash| 23456|\n",
      "|   1004|        Mani|337456|\n",
      "|   1008|      Barath|765456|\n",
      "|   1009|     Patrick| 98765|\n",
      "+-------+------------+------+\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [Roll_no#40, Student_name#41, Mobile#42], [Roll_no#120, Student_name#121, Mobile#122], LeftSemi, BuildRight, false\n",
      ":- *(2) Filter ((isnotnull(Roll_no#40) AND isnotnull(Student_name#41)) AND isnotnull(Mobile#42))\n",
      ":  +- FileScan csv [Roll_no#40,Student_name#41,Mobile#42] Batched: false, DataFilters: [isnotnull(Roll_no#40), isnotnull(Student_name#41), isnotnull(Mobile#42)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/venka/PycharmProjects/pythonProject/dataset/IntSetJoin1..., PartitionFilters: [], PushedFilters: [IsNotNull(Roll_no), IsNotNull(Student_name), IsNotNull(Mobile)], ReadSchema: struct<Roll_no:int,Student_name:string,Mobile:int>\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(input[0, int, false], input[1, string, false], input[2, int, false]),false), [plan_id=823]\n",
      "   +- *(1) Filter ((isnotnull(Roll_no#120) AND isnotnull(Student_name#121)) AND isnotnull(Mobile#122))\n",
      "      +- FileScan csv [Roll_no#120,Student_name#121,Mobile#122] Batched: false, DataFilters: [isnotnull(Roll_no#120), isnotnull(Student_name#121), isnotnull(Mobile#122)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/venka/PycharmProjects/pythonProject/dataset/IntSetJoin2..., PartitionFilters: [], PushedFilters: [IsNotNull(Roll_no), IsNotNull(Student_name), IsNotNull(Mobile)], ReadSchema: struct<Roll_no:int,Student_name:string,Mobile:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#leftSemi - whatever is common in leftside of table is returned\n",
    "masterdf.join(dailydf, on=[\"Roll_no\",\"Student_name\",\"Mobile\"],how=\"leftSemi\").show()\n",
    "\n",
    "masterdf.join(dailydf, on=[\"Roll_no\",\"Student_name\",\"Mobile\"],how=\"leftSemi\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "626cb6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+\n",
      "|Roll_no|Student_name|Mobile|\n",
      "+-------+------------+------+\n",
      "|   1005|       Manju|820456|\n",
      "|   1006|      Magesh|987456|\n",
      "|   1007|        Balu|654321|\n",
      "+-------+------------+------+\n",
      "\n",
      "== Physical Plan ==\n",
      "*(5) Project [Roll_no#40, Student_name#41, Mobile#42]\n",
      "+- Generate replicaterows(sum#448L, Roll_no#40, Student_name#41, Mobile#42), [Roll_no#40, Student_name#41, Mobile#42], false, [Roll_no#40, Student_name#41, Mobile#42]\n",
      "   +- *(4) Filter (isnotnull(sum#448L) AND (sum#448L > 0))\n",
      "      +- *(4) HashAggregate(keys=[Roll_no#40, Student_name#41, Mobile#42], functions=[sum(vcol#445L)])\n",
      "         +- Exchange hashpartitioning(Roll_no#40, Student_name#41, Mobile#42, 3), ENSURE_REQUIREMENTS, [plan_id=962]\n",
      "            +- *(3) HashAggregate(keys=[Roll_no#40, Student_name#41, Mobile#42], functions=[partial_sum(vcol#445L)])\n",
      "               +- Union\n",
      "                  :- *(1) Project [1 AS vcol#445L, Roll_no#40, Student_name#41, Mobile#42]\n",
      "                  :  +- FileScan csv [Roll_no#40,Student_name#41,Mobile#42] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/venka/PycharmProjects/pythonProject/dataset/IntSetJoin1..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Roll_no:int,Student_name:string,Mobile:int>\n",
      "                  +- *(2) Project [-1 AS vcol#446L, Roll_no#120, Student_name#121, Mobile#122]\n",
      "                     +- FileScan csv [Roll_no#120,Student_name#121,Mobile#122] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/venka/PycharmProjects/pythonProject/dataset/IntSetJoin2..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Roll_no:int,Student_name:string,Mobile:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get records from one file\n",
    "\n",
    "#subtract and itersect to be used, have same number of columns otherwise exception is shown\n",
    "masterdf.exceptAll(dailydf).show()\n",
    "masterdf.exceptAll(dailydf).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad818a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+\n",
      "|Roll_no|Student_name|Mobile|\n",
      "+-------+------------+------+\n",
      "|   1005|       Manju|820456|\n",
      "|   1006|      Magesh|987456|\n",
      "|   1007|        Balu|654321|\n",
      "+-------+------------+------+\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[Roll_no#40, Student_name#41, Mobile#42], functions=[])\n",
      "+- Exchange hashpartitioning(Roll_no#40, Student_name#41, Mobile#42, 3), ENSURE_REQUIREMENTS, [plan_id=1067]\n",
      "   +- *(1) HashAggregate(keys=[Roll_no#40, Student_name#41, Mobile#42], functions=[])\n",
      "      +- *(1) BroadcastHashJoin [coalesce(Roll_no#40, 0), isnull(Roll_no#40), coalesce(Student_name#41, ), isnull(Student_name#41), coalesce(Mobile#42, 0), isnull(Mobile#42)], [coalesce(Roll_no#120, 0), isnull(Roll_no#120), coalesce(Student_name#121, ), isnull(Student_name#121), coalesce(Mobile#122, 0), isnull(Mobile#122)], LeftAnti, BuildRight, false\n",
      "         :- FileScan csv [Roll_no#40,Student_name#41,Mobile#42] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/venka/PycharmProjects/pythonProject/dataset/IntSetJoin1..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Roll_no:int,Student_name:string,Mobile:int>\n",
      "         +- BroadcastExchange HashedRelationBroadcastMode(List(coalesce(input[0, int, true], 0), isnull(input[0, int, true]), coalesce(input[1, string, true], ), isnull(input[1, string, true]), coalesce(input[2, int, true], 0), isnull(input[2, int, true])),false), [plan_id=1056]\n",
      "            +- FileScan csv [Roll_no#120,Student_name#121,Mobile#122] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/venka/PycharmProjects/pythonProject/dataset/IntSetJoin2..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Roll_no:int,Student_name:string,Mobile:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get record from one file, indirectly calls leftanti\n",
    "masterdf.subtract(dailydf).show()\n",
    "masterdf.subtract(dailydf).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d43c8dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------+\n",
      "|Roll_no|Student_name|Mobile|\n",
      "+-------+------------+------+\n",
      "|   1005|       Manju|820456|\n",
      "|   1006|      Magesh|987456|\n",
      "|   1007|        Balu|654321|\n",
      "+-------+------------+------+\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [Roll_no#40, Student_name#41, Mobile#42], [Roll_no#120, Student_name#121, Mobile#122], LeftAnti, BuildRight, false\n",
      ":- FileScan csv [Roll_no#40,Student_name#41,Mobile#42] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/venka/PycharmProjects/pythonProject/dataset/IntSetJoin1..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Roll_no:int,Student_name:string,Mobile:int>\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(input[0, int, false], input[1, string, false], input[2, int, false]),false), [plan_id=1150]\n",
      "   +- *(1) Filter ((isnotnull(Roll_no#120) AND isnotnull(Student_name#121)) AND isnotnull(Mobile#122))\n",
      "      +- FileScan csv [Roll_no#120,Student_name#121,Mobile#122] Batched: false, DataFilters: [isnotnull(Roll_no#120), isnotnull(Student_name#121), isnotnull(Mobile#122)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/venka/PycharmProjects/pythonProject/dataset/IntSetJoin2..., PartitionFilters: [], PushedFilters: [IsNotNull(Roll_no), IsNotNull(Student_name), IsNotNull(Mobile)], ReadSchema: struct<Roll_no:int,Student_name:string,Mobile:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get record from one file\n",
    "masterdf.join(dailydf,on=[\"Roll_no\",\"Student_name\",\"Mobile\"],how=\"leftanti\").show()\n",
    "masterdf.join(dailydf,on=[\"Roll_no\",\"Student_name\",\"Mobile\"],how=\"leftanti\").explain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
