{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa84cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87cd9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.streaming import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"multi\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f024d7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---------+----+\n",
      "|Name|age|education|Year|\n",
      "+----+---+---------+----+\n",
      "|Mike| 28|       BE|2014|\n",
      "|Jack| 43|      MBA|2000|\n",
      "+----+---+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql adaptive query execution adaptive.coalescePartitions.enabled will makr paritions dynamic\n",
    "sc.setLogLevel(\"Error\")\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",3)\n",
    "spark.conf.get(\"spark.sql.shuffle.partitions\")\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\",\"false\")\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\",\"false\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\",True)\n",
    "spark.conf.set(\"spark.sql.execution.arrow.fallback.enabled\",True)\n",
    "\n",
    "\"\"\"\n",
    "Multi folder read\n",
    "\"\"\"\n",
    "\n",
    "#WithoutInferSchema\n",
    "#headerTrue will read first row and assign column names but type is String for all\n",
    "#spark job created to read first column\n",
    "filepath = \"file:///C:/Users/venka/PycharmProjects/pythonProject/dataset/\"\n",
    "df = spark.read.option(\"header\",True).csv(filepath + \"Multi/Data1/file1.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a47dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23d2d99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+---------+----+\n",
      "|            Name| age|education|Year|\n",
      "+----------------+----+---------+----+\n",
      "|           Gayle|  40|      BBA|2003|\n",
      "|           Rahul|  24|     B.Sc|2012|\n",
      "|           Dhoni|  38|      MBA|2005|\n",
      "|           Rinku|  26|     B.Ed|2016|\n",
      "|           Rohit|  32|       MS|2010|\n",
      "|          Pollar|  36|     M.Sc|2010|\n",
      "|           Kolhi|  29|       ME|2017|\n",
      "|          Hussey|  43|     Ph.d|2013|\n",
      "|          Parker|  23|       BE|2019|\n",
      "|           Peter|  29|       ME|2013|\n",
      "|            Mike|  28|       BE|2014|\n",
      "|            Jack|  43|      MBA|2000|\n",
      "|         age:Int|NULL|     NULL|NULL|\n",
      "|education:String|NULL|     NULL|NULL|\n",
      "|        Year:Int|NULL|     NULL|NULL|\n",
      "+----------------+----+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Method1 List inputpath\n",
    "filepaths = [\"Multi/Data1/*.csv\",\"Multi/Data2/*.csv\",\"Multi/Data3/*.csv\",\"Multi/DataSchema/*.csv\"]\n",
    "full_filepaths = [os.path.join(filepath, path) for path in filepaths]\n",
    "df1 = spark.read.option(\"header\",True) \\\n",
    "        .csv(full_filepaths)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1693bccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---------+----+\n",
      "|  Name|age|education|Year|\n",
      "+------+---+---------+----+\n",
      "| Gayle| 40|      BBA|2003|\n",
      "| Rahul| 24|     B.Sc|2012|\n",
      "| Dhoni| 38|      MBA|2005|\n",
      "| Rinku| 26|     B.Ed|2016|\n",
      "| Rohit| 32|       MS|2010|\n",
      "|Pollar| 36|     M.Sc|2010|\n",
      "| Kolhi| 29|       ME|2017|\n",
      "|Hussey| 43|     Ph.d|2013|\n",
      "|Parker| 23|       BE|2019|\n",
      "| Peter| 29|       ME|2013|\n",
      "|  Mike| 28|       BE|2014|\n",
      "|  Jack| 43|      MBA|2000|\n",
      "+------+---+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Method2 Use regex pattern\n",
    "df2=spark.read.option(\"header\",True).csv(filepath+\"Multi/Data[1-3]*/*.csv\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89b65bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---------+----+\n",
      "|  Name|age|education|Year|\n",
      "+------+---+---------+----+\n",
      "| Gayle| 40|      BBA|2003|\n",
      "| Rahul| 24|     B.Sc|2012|\n",
      "| Dhoni| 38|      MBA|2005|\n",
      "| Rinku| 26|     B.Ed|2016|\n",
      "| Rohit| 32|       MS|2010|\n",
      "|Pollar| 36|     M.Sc|2010|\n",
      "| Kolhi| 29|       ME|2017|\n",
      "|Hussey| 43|     Ph.d|2013|\n",
      "|Parker| 23|       BE|2019|\n",
      "| Peter| 29|       ME|2013|\n",
      "|  Mike| 28|       BE|2014|\n",
      "|  Jack| 43|      MBA|2000|\n",
      "+------+---+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Method3 with curly braces\n",
    "df3=spark.read.option(\"header\",True).csv(filepath+\"Multi/Data{1,2,3}*/*.csv\")\n",
    "df3.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
